{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay, GPIO, Register, allocate, MMIO\n",
    "import os\n",
    "from convert import *\n",
    "import numpy as np\n",
    "\n",
    "import struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay(\"mnist.bit\")\n",
    "fccip=overlay.fcc_combined_0\n",
    "convip=overlay.conv_combined_0\n",
    "reluip=overlay.relu_combined_0\n",
    "inputip=overlay.InputLayer_0\n",
    "lossip=overlay.loss_derivative_0\n",
    "weightip=overlay.update_weights_0\n",
    "converter=Converter()\n",
    "\n",
    "# overlay?\n",
    "\n",
    "# bck1=overlay.backward_fcc_0\n",
    "# # bck1.register_map\n",
    "\n",
    "# actv_fwd1=overlay.activation_fwd_0\n",
    "# actv_bck1=overlay.activation_bckwd_0\n",
    "\n",
    "# actv_fwd1.register_map\n",
    "fcc_weights=np.load(\"fcc_weights.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer():\n",
    "    def __init__(self,xdim,ydim):\n",
    "\n",
    "        self.xdim=xdim\n",
    "        self.ydim=ydim\n",
    "\n",
    "        self.wbuff=allocate(shape=(xdim*ydim,), dtype='uint16')\n",
    "        self.ybuff=allocate(shape=(ydim,), dtype='uint16')\n",
    "        self.bbuff=allocate(shape=(ydim,), dtype='uint16')\n",
    "        \n",
    "        self.dwbuff=allocate(shape=(xdim*ydim,), dtype='uint16')\n",
    "        self.dybuff=allocate(shape=(ydim,), dtype='uint16')\n",
    "        self.dbbuff=allocate(shape=(ydim,), dtype='uint16')\n",
    "        \n",
    "        self.debug_x=allocate(shape=(xdim), dtype='uint16')\n",
    "        self.debug_dx=allocate(shape=(xdim), dtype='uint16')\n",
    "\n",
    "        self.BASE_ADDRESS_W=self.wbuff.physical_address\n",
    "        self.BASE_ADDRESS_DW=self.dwbuff.physical_address\n",
    "\n",
    "        self.BASE_ADDRESS_B=self.bbuff.physical_address\n",
    "        self.BASE_ADDRESS_DB=self.dbbuff.physical_address\n",
    "        \n",
    "        self.reset_weights()\n",
    "\n",
    "\n",
    "    def get_debug_activations(self):\n",
    "        \n",
    "        x=[]\n",
    "        dx=[]        \n",
    "        for i in range(self.xdim):\n",
    "            x.append(converter.decode(int(self.debug_x[i])))\n",
    "            dx.append(converter.decode(int(self.debug_dx[i])))            \n",
    "        \n",
    "        return x,dx\n",
    "\n",
    "\n",
    "    def initHardware(self,fccip):\n",
    "\n",
    "        self.fccip=fccip\n",
    "        self.fccip.register_map.wt=self.BASE_ADDRESS_W\n",
    "        self.fccip.register_map.dwt=self.BASE_ADDRESS_DW\n",
    "        self.fccip.register_map.b=self.BASE_ADDRESS_B\n",
    "        self.fccip.register_map.db=self.BASE_ADDRESS_DB\n",
    "        self.fccip.register_map.xdim=self.xdim\n",
    "        self.fccip.register_map.ydim=self.ydim\n",
    "        self.fccip.register_map.debug_x= self.debug_x.physical_address\n",
    "        self.fccip.register_map.debug_dx= self.debug_dx.physical_address\n",
    "        self.fccip.register_map.debugip= True\n",
    "        self.fccip.register_map.fwprop=True\n",
    "        \n",
    "    def update_weights(self, weightip, lr):\n",
    "        weightip.register_map.w=self.BASE_ADDRESS_W\n",
    "        weightip.register_map.dw=self.BASE_ADDRESS_DW\n",
    "        weightip.register_map.lr=converter.encode(lr)\n",
    "        weightip.register_map.dim=(self.xdim*self.ydim)\n",
    "        \n",
    "        weightip.write(0x00, 1)\n",
    "        fpga_state = weightip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while fpga_state != 6 and fpga_state != 4:\n",
    "            fpga_state = weightip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                weightip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        weightip.write(0x00, 4)\n",
    "\n",
    "        \n",
    "    def set_weights(self,w,b):        \n",
    "        self.wbuff[:]=[int(converter.encode(el)) for el in w]\n",
    "        self.bbuff[:]=[int(converter.encode(el)) for el in b]\n",
    "        self.wbuff.flush()\n",
    "        self.bbuff.flush()\n",
    "\n",
    "    def reset_weights(self):\n",
    "        for i in range(self.xdim*self.ydim):\n",
    "            self.wbuff[i]=fcc_weights[i]\n",
    "        \n",
    "        for i in range(self.ydim):\n",
    "            self.bbuff[i]=int(converter.encode(0+0.002*i))\n",
    "            \n",
    "        self.wbuff.flush()\n",
    "        self.bbuff.flush()\n",
    "            \n",
    "    def get_weights(self):\n",
    "        \n",
    "        w=[]\n",
    "        b=[]        \n",
    "        for i in range(self.xdim*self.ydim):\n",
    "            w.append(converter.decode(int(self.wbuff[i])))\n",
    "        \n",
    "        for i in range(self.ydim):\n",
    "            b.append(converter.decode(int(self.bbuff[i])))\n",
    "        \n",
    "        return w,b\n",
    "   \n",
    "\n",
    "    def fwprop(self):\n",
    "        \n",
    "        self.fccip.register_map.fwprop=True\n",
    "        self.fccip.write(0x00, 1)\n",
    "        fpga_state = self.fccip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while fpga_state != 6 and fpga_state != 4:\n",
    "            fpga_state = self.fccip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.fccip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        self.fccip.write(0x00, 4)\n",
    "\n",
    "    def bckprop(self):\n",
    "        \n",
    "        self.fccip.register_map.fwprop=False\n",
    "        self.fccip.write(0x00, 1)\n",
    "        fpga_state = self.fccip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while fpga_state != 6 and fpga_state != 4:\n",
    "            fpga_state = self.fccip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.fccip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        self.fccip.write(0x00, 4)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer():\n",
    "    def __init__(self,F,C,H,W,FH,FW):\n",
    "\n",
    "        self.F=F\n",
    "        self.C=C\n",
    "        self.H=H\n",
    "        self.W=W\n",
    "        self.FH=FH\n",
    "        self.FW=FW\n",
    "\n",
    "        self.wbuff=allocate(shape=(F*C*FH*FW,), dtype='uint16')\n",
    "        self.bbuff=allocate(shape=(F,), dtype='uint16')\n",
    "        \n",
    "        self.dwbuff=allocate(shape=(F*C*FH*FW,), dtype='uint16')\n",
    "        self.dbbuff=allocate(shape=(F,), dtype='uint16')\n",
    "\n",
    "        self.BASE_ADDRESS_W=self.wbuff.physical_address\n",
    "        self.BASE_ADDRESS_DW=self.dwbuff.physical_address\n",
    "\n",
    "        self.BASE_ADDRESS_B=self.bbuff.physical_address\n",
    "        self.BASE_ADDRESS_DB=self.dbbuff.physical_address\n",
    "        \n",
    "        self.debug_x=allocate(shape=(C*H*W), dtype='uint16')\n",
    "        self.debug_dx=allocate(shape=(C*H*W), dtype='uint16')\n",
    "        \n",
    "        self.reset_weights()\n",
    "\n",
    "\n",
    "\n",
    "    def initHardware(self,convip):\n",
    "\n",
    "        self.convip=convip\n",
    "        \n",
    "        self.convip.register_map.wt=self.BASE_ADDRESS_W\n",
    "        \n",
    "        self.convip.register_map.dwt=self.BASE_ADDRESS_DW\n",
    "        self.convip.register_map.b=self.BASE_ADDRESS_B\n",
    "        self.convip.register_map.db=self.BASE_ADDRESS_DB\n",
    "        self.convip.register_map.H=self.H\n",
    "        self.convip.register_map.W=self.W\n",
    "        self.convip.register_map.FH=self.FH\n",
    "        self.convip.register_map.FW=self.FW\n",
    "        self.convip.register_map.F=self.F\n",
    "        self.convip.register_map.C=self.C\n",
    "        self.convip.register_map.debugip= True\n",
    "        self.convip.register_map.debug_x= self.debug_x.physical_address\n",
    "        self.convip.register_map.debug_dx= self.debug_dx.physical_address\n",
    "        self.convip.register_map.fwprop=True\n",
    "        \n",
    "    def update_weights(self, weightip, lr):\n",
    "        weightip.register_map.w=self.BASE_ADDRESS_W\n",
    "        weightip.register_map.dw=self.BASE_ADDRESS_DW\n",
    "        weightip.register_map.lr=converter.encode(lr)\n",
    "        weightip.register_map.dim=(self.F*self.C*self.FH*self.FW)\n",
    "        \n",
    "        weightip.write(0x00, 1)\n",
    "        fpga_state = weightip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while fpga_state != 6 and fpga_state != 4:\n",
    "            fpga_state = weightip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                weightip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        weightip.write(0x00, 4)\n",
    "        \n",
    "    def get_debug_activations(self):\n",
    "        \n",
    "        x=[]\n",
    "        dx=[]        \n",
    "        for i in range(self.C*self.H*self.W):\n",
    "            x.append(converter.decode(int(self.debug_x[i])))\n",
    "        \n",
    "        for i in range(self.C*self.H*self.W):\n",
    "            dx.append(converter.decode(int(self.debug_dx[i])))\n",
    "        \n",
    "        return x,dx\n",
    "        \n",
    "\n",
    "        \n",
    "    def set_weights(self,w,b):        \n",
    "        self.wbuff[:]=[int(converter.encode(el)) for el in w]\n",
    "        self.bbuff[:]=[int(converter.encode(el)) for el in b]\n",
    "        self.wbuff.flush()\n",
    "        self.bbuff.flush()\n",
    "\n",
    "    def reset_weights(self):\n",
    "        for i in range(self.F*self.C*self.FH*self.FW):\n",
    "            self.wbuff[i]=int(converter.encode(0.1+0.002*i))\n",
    "        \n",
    "        for i in range(self.F):\n",
    "            self.bbuff[i]=int(converter.encode(0.0+0.002*i))\n",
    "            \n",
    "        self.wbuff.flush()\n",
    "        self.bbuff.flush()\n",
    "\n",
    "            \n",
    "    def get_weights(self):\n",
    "        \n",
    "        w=[]\n",
    "        b=[]        \n",
    "        for i in range(self.F*self.C*self.FH*self.FW):\n",
    "            w.append(converter.decode(int(self.wbuff[i])))\n",
    "        \n",
    "        for i in range(self.F):\n",
    "            b.append(converter.decode(int(self.bbuff[i])))\n",
    "        \n",
    "        return w,b\n",
    "    \n",
    "    def get_weight_grads(self):\n",
    "        \n",
    "        dw=[]\n",
    "        db=[]        \n",
    "        for i in range(self.F*self.C*self.FH*self.FW):\n",
    "            dw.append(converter.decode(int(self.dwbuff[i])))\n",
    "        \n",
    "        for i in range(self.F):\n",
    "            db.append(converter.decode(int(self.dbbuff[i])))\n",
    "        \n",
    "        return dw,db\n",
    "   \n",
    "\n",
    "    def fwprop(self):\n",
    "        \n",
    "        self.convip.register_map.fwprop=True\n",
    "        self.convip.write(0x00, 1)\n",
    "        fpga_state = self.convip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while fpga_state != 6 and fpga_state != 4:\n",
    "            fpga_state = self.convip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.convip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "\n",
    "    def bckprop(self):\n",
    "        \n",
    "        self.convip.register_map.fwprop=False\n",
    "        self.convip.write(0x00, 1)\n",
    "        fpga_state = self.convip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while fpga_state != 6 and fpga_state != 4:\n",
    "            fpga_state = self.convip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.convip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        self.convip.write(0x00, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReluLayer():\n",
    "    def __init__(self,dim):\n",
    "\n",
    "        self.dim=dim\n",
    "        \n",
    "        self.debug_x=allocate(shape=(dim), dtype='uint16')\n",
    "        self.debug_dx=allocate(shape=(dim), dtype='uint16')\n",
    "\n",
    "\n",
    "    def initHardware(self,reluip):\n",
    "\n",
    "        self.reluip=reluip\n",
    "        self.reluip.register_map.dim=self.dim\n",
    "        self.reluip.register_map.debug_x= self.debug_x.physical_address\n",
    "        self.reluip.register_map.debug_dx= self.debug_dx.physical_address\n",
    "        self.reluip.register_map.debugip=True\n",
    "        \n",
    "    def get_debug_activations(self):\n",
    "        \n",
    "        x=[]\n",
    "        dx=[]\n",
    "        \n",
    "        for i in range(self.dim):\n",
    "            x.append(converter.decode(int(self.debug_x[i])))\n",
    "            dx.append(converter.decode(int(self.debug_dx[i])))\n",
    "        \n",
    "        return x,dx\n",
    "        \n",
    "        \n",
    "    def update_weights(self,weightip,learning_rate):\n",
    "        return\n",
    "   \n",
    "\n",
    "    def fwprop(self):\n",
    "        \n",
    "        self.reluip.register_map.fwprop=True\n",
    "        self.reluip.write(0x00, 1)\n",
    "        fpga_state = self.reluip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while fpga_state != 6 and fpga_state != 4:\n",
    "            fpga_state = self.reluip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.reluip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        self.reluip.write(0x00, 4)\n",
    "\n",
    "    def bckprop(self):\n",
    "        \n",
    "        self.reluip.register_map.fwprop=False\n",
    "        self.reluip.write(0x00, 1)\n",
    "        fpga_state = self.reluip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while fpga_state != 6 and fpga_state != 4:\n",
    "            fpga_state = self.reluip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.reluip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        self.reluip.write(0x00, 4)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class Neural_Net():\n",
    "\n",
    "    def __init__(self, fccip, convip, reluip,inputip,lossip,weightip,xdim,ydim):\n",
    "\n",
    "        self.layers=[]\n",
    "        self.layer_names=[]\n",
    "        self.layer_base_addresses=[]\n",
    "        self.nlayers=0\n",
    "        self.fccip=fccip\n",
    "        self.convip=convip\n",
    "        self.reluip=reluip\n",
    "        self.inputip=inputip\n",
    "        self.lossip=lossip\n",
    "        self.weightip=weightip\n",
    "        \n",
    "        self.xbuff=allocate(shape=(xdim,), dtype='uint16')\n",
    "        self.dxbuff=allocate(shape=(xdim,), dtype='uint16')\n",
    "        self.ybuff=allocate(shape=(ydim,), dtype='uint16')\n",
    "        self.dybuff=allocate(shape=(ydim,), dtype='uint16')\n",
    "        \n",
    "        self.xdim=xdim\n",
    "        self.ydim=ydim \n",
    "        \n",
    "        self.dx_ddr_addr=self.dxbuff.physical_address\n",
    "                \n",
    "        self.x_ddr_addr=self.xbuff.physical_address\n",
    "        \n",
    "        self.dy_ddr_addr=self.dybuff.physical_address\n",
    "        \n",
    "        self.y_ddr_addr=self.ybuff.physical_address\n",
    "        \n",
    "        self.inputip.register_map.x=self.x_ddr_addr\n",
    "        self.inputip.register_map.dx=self.dx_ddr_addr\n",
    "        self.inputip.register_map.dim=xdim\n",
    "        self.inputip.register_map.ddrtobram=1\n",
    "        \n",
    "        self.lossip.register_map.x_ddr=self.y_ddr_addr\n",
    "        self.lossip.register_map.dx_ddr=self.dy_ddr_addr\n",
    "        self.lossip.register_map.dim=ydim\n",
    "        self.lossip.register_map.writetoddr=1\n",
    "        self.lossip.register_map.ddrtobram=1\n",
    "        self.lossip.register_map.y=0\n",
    "        self.lossip.register_map.N=0\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def add_fcc(self,xdim,ydim):\n",
    "        layer=FullyConnectedLayer(xdim,ydim)\n",
    "        self.layers.append(layer)\n",
    "        self.layer_names.append(\"fcc\")\n",
    "        self.nlayers+=1\n",
    "        \n",
    "    def add_conv(self,F,C,H,W,FH,FW):\n",
    "        layer=ConvolutionLayer(F,C,H,W,FH,FW)\n",
    "        self.layers.append(layer)\n",
    "        self.layer_names.append(\"conv\")\n",
    "        self.nlayers+=1\n",
    "        \n",
    "    def add_relu(self,dim):\n",
    "\n",
    "        layer=ReluLayer(dim)\n",
    "        self.layers.append(layer)\n",
    "        self.layer_names.append(\"relu\")\n",
    "        self.nlayers+=1\n",
    "        \n",
    "    def update_weights(self, lr):\n",
    "        \n",
    "        for i in range(self.nlayers):\n",
    "            self.layers[i].update_weights(self.weightip,lr)\n",
    "       \n",
    "    def write_input(self,xvals):\n",
    "        print(xvals)\n",
    "        for i in range(self.xdim):\n",
    "            self.xbuff[i]= int(converter.encode(xvals[i]))\n",
    "        self.xbuff.flush()\n",
    "        \n",
    "        self.inputip.register_map.ddrtobram=1\n",
    "        \n",
    "        self.inputip.write(0x00,1)\n",
    "        ip_state = self.inputip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while ip_state != 6 and ip_state != 4:\n",
    "            ip_state = self.inputip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.inputip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        self.inputip.write(0x00, 4)\n",
    "                    \n",
    "        \n",
    "                \n",
    "    def fetch_input(self):\n",
    "        #########################################\n",
    "        \n",
    "        self.inputip.register_map.ddrtobram=0\n",
    "        \n",
    "        self.inputip.write(0x00,1)\n",
    "        ip_state = self.inputip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while ip_state != 6 and ip_state != 4:\n",
    "            ip_state = self.inputip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.inputip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        self.inputip.write(0x00, 4)\n",
    "        \n",
    "        xvals=[]\n",
    "        dxvals=[]\n",
    "        for i in range(self.xdim):\n",
    "            xvals.append(converter.decode(int(self.xbuff[i])))\n",
    "                         \n",
    "        for i in range(self.xdim):\n",
    "            dxvals.append(converter.decode(int(self.dxbuff[i])))\n",
    "        \n",
    "        return xvals,dxvals\n",
    "        \n",
    "        \n",
    "    def write_output(self,yvals, dyvals):\n",
    "        \n",
    "        for i in range(self.ydim): \n",
    "            ybuff[i]= int(converter.encode(yvals[i]))\n",
    "            dybuff[i]= int(converter.encode(dyvals[i]))\n",
    "            \n",
    "        ybuff.flush()\n",
    "        dybuff.flush()\n",
    "        \n",
    "        self.lossip.register_map.writetoddr=1\n",
    "        self.lossip.register_map.ddrtobram=1\n",
    "        \n",
    "        self.lossip.write(0x00,1)\n",
    "        ip_state = self.lossip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while ip_state != 6 and ip_state != 4:\n",
    "            ip_state = self.lossip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.lossip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        self.lossip.write(0x00, 4)\n",
    "                    \n",
    "        \n",
    "\n",
    "        \n",
    "    def fetch_output(self):\n",
    "        \n",
    "        self.lossip.register_map.writetoddr=1\n",
    "        self.lossip.register_map.ddrtobram=0\n",
    "        \n",
    "        self.lossip.write(0x00,1)\n",
    "        ip_state = self.lossip.read(0x00)\n",
    "\n",
    "        max_try = 1000000\n",
    "        while ip_state != 6 and ip_state != 4:\n",
    "            ip_state = self.lossip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.lossip.write(0x00, 4)\n",
    "                break\n",
    "\n",
    "        self.lossip.write(0x00, 4)\n",
    "        \n",
    "        \n",
    "        yvals=[]\n",
    "        for i in range(self.ydim):\n",
    "            yvals.append(converter.decode(int(self.ybuff[i])))\n",
    "        dyvals=[]\n",
    "        for i in range(self.ydim):\n",
    "            dyvals.append(converter.decode(int(self.dybuff[i])))\n",
    "        \n",
    "        return yvals,dyvals\n",
    "    \n",
    "    \n",
    "    def calculate_loss_gradient(self,label, batch_size):\n",
    "        \n",
    "        self.lossip.register_map.writetoddr=0\n",
    "        self.lossip.register_map.y=label\n",
    "        self.lossip.register_map.N=batch_size\n",
    "        \n",
    "        self.lossip.write(0x00,1)\n",
    "        ip_state = self.lossip.read(0x00)\n",
    "        print(\"yoyo\")\n",
    "\n",
    "        max_try = 1000000\n",
    "        while ip_state != 6 and ip_state != 4:\n",
    "            ip_state = self.lossip.read(0x00)\n",
    "            max_try = max_try -1\n",
    "            if max_try == 0:\n",
    "                print(\"ERROR: Can't go ahead\")\n",
    "                self.lossip.write(0x00, 4)\n",
    "                break\n",
    "        \n",
    "\n",
    "        self.lossip.write(0x00, 4)\n",
    "        loss= self.lossip.register_map.ap_return\n",
    "        loss=converter.decode(int(loss))\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    def predict(self,x):\n",
    "        \n",
    "        self.runfwprop(x)\n",
    "        yvals, dyvals= self.fetch_output()\n",
    "            \n",
    "        return yvals\n",
    "    \n",
    "        \n",
    "    def runfwprop(self,x):\n",
    "        \n",
    "        self.write_input(x)\n",
    "        print(\"written x\")\n",
    "        \n",
    "        for i in range(self.nlayers):\n",
    "            if self.layer_names[i] == \"fcc\":\n",
    "                print(\"fcc\")\n",
    "                \n",
    "                self.layers[i].initHardware(self.fccip)\n",
    "                self.layers[i].fwprop()\n",
    "            elif self.layer_names[i] == \"conv\":\n",
    "                print(\"conv\")\n",
    "                self.layers[i].initHardware(self.convip)\n",
    "                self.layers[i].fwprop()\n",
    "            else:\n",
    "                print(\"relu\")\n",
    "                self.layers[i].initHardware(self.reluip)\n",
    "                self.layers[i].fwprop()\n",
    "                \n",
    "\n",
    "\n",
    "    def runbackprop(self):\n",
    "      \n",
    "        for i in range(self.nlayers):\n",
    "            j=self.nlayers-i-1\n",
    "            self.layers[j].bckprop()\n",
    "    \n",
    "    \n",
    "    def train(self,x,y,epochs,learning_rate, batch_size):\n",
    "        print(\"inside training\")\n",
    "        x1=x.copy()\n",
    "        y1=y.copy()\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            \n",
    "            for j in range(x1.shape[0]):\n",
    "                print(\"yo\")\n",
    "                self.runfwprop(x1[j])\n",
    "                print(\"done fwprop\")\n",
    "                loss=self.calculate_loss_gradient(y1[j],batch_size)\n",
    "                print(loss)\n",
    "                self.runbackprop()\n",
    "                self.update_weights(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.load('x_train.npy')\n",
    "y_train=np.load('y_train.npy')\n",
    "x_test=np.load('x_test.npy')\n",
    "y_test=np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn=Neural_Net(fccip, convip,reluip,inputip,lossip,weightip,784,10)\n",
    "nn.add_conv(5,1,28,28,5,5)\n",
    "nn.add_relu(2880)\n",
    "nn.add_fcc(2880,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside training\n",
      "yo\n"
     ]
    }
   ],
   "source": [
    "nn.train(x_train,y_train,10,0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.49731445]), array([0.64611816]), array([0.54040527])]\n",
      "[array([0.31201172]), array([-0.63793945]), array([0.32568359])]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.18041992]), array([0.31689453]), array([0.32922363]), array([0.21118164])]\n",
      "[array([0.32849121]), array([-0.33886719]), array([-0.34423828]), array([0.35046387])]\n"
     ]
    }
   ],
   "source": [
    "x,dx = nn.layers[1].get_debug_activations()\n",
    "print(x)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b=nn.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.1138916]), array([0.11694336])]\n",
      "[array([0.])]\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1,2,3,4]\n",
    "x1=allocate(shape=(4,),dtype='uint16')\n",
    "x2=allocate(shape=(4,),dtype='uint16')\n",
    "\n",
    "for i in range(4):\n",
    "    x1[i]= x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegisterMap {\n",
       "  CTRL = Register(AP_START=0, AP_DONE=0, AP_IDLE=1, AP_READY=0, RESERVED_1=0, AUTO_RESTART=0, RESERVED_2=0),\n",
       "  GIER = Register(Enable=0, RESERVED=0),\n",
       "  IP_IER = Register(CHAN0_INT_EN=0, CHAN1_INT_EN=0, RESERVED=0),\n",
       "  IP_ISR = Register(CHAN0_INT_ST=0, CHAN1_INT_ST=0, RESERVED=0),\n",
       "  ap_return = Register(ap_return=0, RESERVED=0),\n",
       "  x_ddr = Register(x_ddr=378007552),\n",
       "  dx_ddr = Register(dx_ddr=378011648),\n",
       "  y = Register(y=0),\n",
       "  dim = Register(dim=10),\n",
       "  writetoddr = Register(writetoddr=1, RESERVED=0),\n",
       "  ddrtobram = Register(ddrtobram=1, RESERVED=0)\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossip.register_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=allocate(shape=(4,),dtype='uint16')\n",
    "x2=allocate(shape=(4,),dtype='uint16')\n",
    "\n",
    "x1[:]=[converter.encode(0.1),converter.encode(0.4),converter.encode(0.1),converter.encode(0.1)]\n",
    "y=1\n",
    "N=1\n",
    "x2[:]=[0,0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossip.register_map.x_ddr=x1.physical_address\n",
    "lossip.register_map.dx_ddr=x2.physical_address\n",
    "lossip.register_map.y=y\n",
    "lossip.register_map.writetoddr=1\n",
    "lossip.register_map.ddrtobram=0\n",
    "lossip.register_map.dim=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossip.write(0x00,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49938965]\n",
      "[0.49938965]\n",
      "[0.49938965]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(converter.decode(int(x1[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt=np.zeros(28800)\n",
    "for i in range(28800):\n",
    "    wt[i]=int(converter.encode(0.2+0.002*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"fcc_weights.npy\",wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
